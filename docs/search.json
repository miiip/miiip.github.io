[
  {
    "objectID": "posts/is-it-hacked.html",
    "href": "posts/is-it-hacked.html",
    "title": "Is it hacked?",
    "section": "",
    "text": "In this short tutorial, we construct a simple classifier for detecting web defacement using fast.ai library. Currently, I‚Äôm taking Jeremy Howard‚Äôs course (Practical Deep Learning for Coders - Part 1) and I‚Äôm thrilled about it. I‚Äôve coded various DL models in the past (especially for cybersecurity), but I only used TensorFlow. Recently, I wanted to try PyTorch since it seems that it takes over the market. In the past, I had heard of fastai as a PyTorch-based library, but because I was using TensorFlow, I didn‚Äôt pay much attention to it. Now, I‚Äôm impressed by what this library can do and I want to share this with you. Don‚Äôt expect to see a state-of-the-art model, I‚Äôm only experimenting with fastai for cybersecurity related problems üòÅ\nJust to be more clear: you know when a website is hacked and the hackers display some message on the home page? \nThis is web defacement and this we are trying to detect it. Why? Well, if your site was defaced, the first thing you do is to put it in maintenance mode. Wouldn‚Äôt it be nice if you had a DL model that would warn you instantly when a website has been defaced? If you want to know how you might do that, keep reading ü§ì\n\n\n\nWe will use duckduckgo_search to construct our dataset of defaced and non-defaced websites.\n\nfrom duckduckgo_search import ddg_images\nfrom fastcore.all import *\nfrom fastai.vision.widgets import *\n\n\ndef search_images(term, max_images=50):\n    print(f\"Searching for '{term}'\")\n    return L(ddg_images(term, max_results=max_images)).itemgot('image')\n\nHere is an example:\n\nurls = search_images('example of defaced webpage', max_images=1)\nurls[0]\n\nSearching for 'example of defaced webpage'\n\n\n'https://blog.sucuri.net/wp-content/uploads/2020/04/image1-600x419.png'\n\n\nNow, we download the image from that URL and saved it locally in a file named defaced.jpg. To do this, we use another ‚Äúfast‚Äù library called fastdownload.\n\nfrom fastdownload import download_url\ndest = 'defaced.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nPath('defaced.jpg')\n\n\nTo check if we saved the right image, we open it using PIL. The to_thumb function produces a 256x256 thumbnail version of the image.\n\nfrom fastai.vision.all import *\nim = Image.open(dest)\nim.to_thumb(256,256)\n\n\n\n\nNow we repeat for a non-defaced website.\n\ndownload_url(search_images('example of normal webpage', max_images=1)[0], 'non-defaced.jpg', show_progress=False)\nImage.open('non-defaced.jpg').to_thumb(256,256)\n\nSearching for 'example of normal webpage'\n\n\n\n\n\nLet‚Äôs build our dataset. We search for defaced and on-defaced websites.\n\nsearches = ['defaced website','nice homepage site example']\nlocal = ['d', 'nd']\npath = Path('defaced_or_not')\nfrom time import sleep\n\nfor idx in range(2):\n    dest = (path/local[idx])\n    print(path, local[idx] , dest)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(searches[idx]))\n    sleep(10)\n    resize_images(path/local[idx], max_size=400, dest=path/local[idx])\n\nDelete all images that were downloaded incorrectly.\n\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n\n0\n\n\n\nprint(len(os.listdir(path/'d')))\nprint(len(os.listdir(path/'nd')))\n\n47\n48\n\n\nWe have 47 images of defaced websites and 48 images of non-defaced websites.\n\n\n\nTo train the model we first construct a DataBlock. In a DataBlock we specify how to split the data in training and validation, how to label the training images (defaced or non-defaced) and how to pre-process the images (for example, we resize all the images using a common dimension). Using fastai we can make all of these in a single line of code ü•π.\n\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=9)\n\n\n\n\nNow we are ready to train the model. Here is the trick: we use something called transfer learning. We borrow the knowledge from a very big pre-trained model like resnet18 and customize that knowledge for our use case. It‚Äôs like getting knowledge about mathematics in general and then getting specialized in derivatives\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(8)\n\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.430695\n0.622086\n0.315789\n00:07\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.767509\n0.755880\n0.368421\n00:01\n\n\n1\n0.668098\n0.829260\n0.368421\n00:00\n\n\n2\n0.580183\n0.730606\n0.315789\n00:00\n\n\n3\n0.442123\n0.641195\n0.263158\n00:00\n\n\n4\n0.366080\n0.600636\n0.263158\n00:00\n\n\n5\n0.301277\n0.524480\n0.210526\n00:00\n\n\n6\n0.254276\n0.463378\n0.105263\n00:00\n\n\n7\n0.218404\n0.426965\n0.105263\n00:00\n\n\n\n\n\nWe get almost 90% accuracy on the validation dataset which is great for a first try ü•≥\nHere is the confusion matrix for the validation dataset. The confusion matrix tells us the following:\n\nHow many defaced websites were labeled as defaced (True Positives)\nHow many defaced websites were labeled as non-defaced (False negatives)\nHow many non-defaced websites were labeled as defaced (False positives)\nHow many non-defaced websites were labeled as non-defaced (True Negatives)\n\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet‚Äôs see what our model thinks about that defaced.jpg we downloaded at the start:\n\nis_defaced,_,probs = learn.predict(PILImage.create('defaced.jpg'))\nprint(f\"This is a: {is_defaced}.\")\nprint(f\"Probability it's a defaced: {probs[0]:.4f}\")\n\n\n\n\n\n\n\n\nThis is a: d.\nProbability it's a defaced: 0.9962\n\n\n\n\n\nIn this short blog post, we constructed a simple classifier to detect web defacement. Our classifier gets 80% accuracy on the validation dataset. I will continue to improve it as I follow the course, so stay tuned üòé\nThis post is based on the first lab of the fast.ai coure so thank you Jeremy Howard üòÉ"
  },
  {
    "objectID": "posts/is-it-hacked.html#introduction",
    "href": "posts/is-it-hacked.html#introduction",
    "title": "Is it hacked?",
    "section": "",
    "text": "In this short tutorial, we construct a simple classifier for detecting web defacement using fast.ai library. Currently, I‚Äôm taking Jeremy Howard‚Äôs course (Practical Deep Learning for Coders - Part 1) and I‚Äôm thrilled about it. I‚Äôve coded various DL models in the past (especially for cybersecurity), but I only used TensorFlow. Recently, I wanted to try PyTorch since it seems that it takes over the market. In the past, I had heard of fastai as a PyTorch-based library, but because I was using TensorFlow, I didn‚Äôt pay much attention to it. Now, I‚Äôm impressed by what this library can do and I want to share this with you. Don‚Äôt expect to see a state-of-the-art model, I‚Äôm only experimenting with fastai for cybersecurity related problems üòÅ\nJust to be more clear: you know when a website is hacked and the hackers display some message on the home page? \nThis is web defacement and this we are trying to detect it. Why? Well, if your site was defaced, the first thing you do is to put it in maintenance mode. Wouldn‚Äôt it be nice if you had a DL model that would warn you instantly when a website has been defaced? If you want to know how you might do that, keep reading ü§ì"
  },
  {
    "objectID": "posts/is-it-hacked.html#step-1-download-images-of-defaced-and-non-defaced-websites",
    "href": "posts/is-it-hacked.html#step-1-download-images-of-defaced-and-non-defaced-websites",
    "title": "Is it hacked?",
    "section": "",
    "text": "We will use duckduckgo_search to construct our dataset of defaced and non-defaced websites.\n\nfrom duckduckgo_search import ddg_images\nfrom fastcore.all import *\nfrom fastai.vision.widgets import *\n\n\ndef search_images(term, max_images=50):\n    print(f\"Searching for '{term}'\")\n    return L(ddg_images(term, max_results=max_images)).itemgot('image')\n\nHere is an example:\n\nurls = search_images('example of defaced webpage', max_images=1)\nurls[0]\n\nSearching for 'example of defaced webpage'\n\n\n'https://blog.sucuri.net/wp-content/uploads/2020/04/image1-600x419.png'\n\n\nNow, we download the image from that URL and saved it locally in a file named defaced.jpg. To do this, we use another ‚Äúfast‚Äù library called fastdownload.\n\nfrom fastdownload import download_url\ndest = 'defaced.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nPath('defaced.jpg')\n\n\nTo check if we saved the right image, we open it using PIL. The to_thumb function produces a 256x256 thumbnail version of the image.\n\nfrom fastai.vision.all import *\nim = Image.open(dest)\nim.to_thumb(256,256)\n\n\n\n\nNow we repeat for a non-defaced website.\n\ndownload_url(search_images('example of normal webpage', max_images=1)[0], 'non-defaced.jpg', show_progress=False)\nImage.open('non-defaced.jpg').to_thumb(256,256)\n\nSearching for 'example of normal webpage'\n\n\n\n\n\nLet‚Äôs build our dataset. We search for defaced and on-defaced websites.\n\nsearches = ['defaced website','nice homepage site example']\nlocal = ['d', 'nd']\npath = Path('defaced_or_not')\nfrom time import sleep\n\nfor idx in range(2):\n    dest = (path/local[idx])\n    print(path, local[idx] , dest)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(searches[idx]))\n    sleep(10)\n    resize_images(path/local[idx], max_size=400, dest=path/local[idx])\n\nDelete all images that were downloaded incorrectly.\n\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n\n0\n\n\n\nprint(len(os.listdir(path/'d')))\nprint(len(os.listdir(path/'nd')))\n\n47\n48\n\n\nWe have 47 images of defaced websites and 48 images of non-defaced websites."
  },
  {
    "objectID": "posts/is-it-hacked.html#step-2-train-the-model",
    "href": "posts/is-it-hacked.html#step-2-train-the-model",
    "title": "Is it hacked?",
    "section": "",
    "text": "To train the model we first construct a DataBlock. In a DataBlock we specify how to split the data in training and validation, how to label the training images (defaced or non-defaced) and how to pre-process the images (for example, we resize all the images using a common dimension). Using fastai we can make all of these in a single line of code ü•π.\n\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=9)\n\n\n\n\nNow we are ready to train the model. Here is the trick: we use something called transfer learning. We borrow the knowledge from a very big pre-trained model like resnet18 and customize that knowledge for our use case. It‚Äôs like getting knowledge about mathematics in general and then getting specialized in derivatives\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(8)\n\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.430695\n0.622086\n0.315789\n00:07\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.767509\n0.755880\n0.368421\n00:01\n\n\n1\n0.668098\n0.829260\n0.368421\n00:00\n\n\n2\n0.580183\n0.730606\n0.315789\n00:00\n\n\n3\n0.442123\n0.641195\n0.263158\n00:00\n\n\n4\n0.366080\n0.600636\n0.263158\n00:00\n\n\n5\n0.301277\n0.524480\n0.210526\n00:00\n\n\n6\n0.254276\n0.463378\n0.105263\n00:00\n\n\n7\n0.218404\n0.426965\n0.105263\n00:00\n\n\n\n\n\nWe get almost 90% accuracy on the validation dataset which is great for a first try ü•≥\nHere is the confusion matrix for the validation dataset. The confusion matrix tells us the following:\n\nHow many defaced websites were labeled as defaced (True Positives)\nHow many defaced websites were labeled as non-defaced (False negatives)\nHow many non-defaced websites were labeled as defaced (False positives)\nHow many non-defaced websites were labeled as non-defaced (True Negatives)\n\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()"
  },
  {
    "objectID": "posts/is-it-hacked.html#step-3-use-the-model",
    "href": "posts/is-it-hacked.html#step-3-use-the-model",
    "title": "Is it hacked?",
    "section": "",
    "text": "Let‚Äôs see what our model thinks about that defaced.jpg we downloaded at the start:\n\nis_defaced,_,probs = learn.predict(PILImage.create('defaced.jpg'))\nprint(f\"This is a: {is_defaced}.\")\nprint(f\"Probability it's a defaced: {probs[0]:.4f}\")\n\n\n\n\n\n\n\n\nThis is a: d.\nProbability it's a defaced: 0.9962"
  },
  {
    "objectID": "posts/is-it-hacked.html#conclusions",
    "href": "posts/is-it-hacked.html#conclusions",
    "title": "Is it hacked?",
    "section": "",
    "text": "In this short blog post, we constructed a simple classifier to detect web defacement. Our classifier gets 80% accuracy on the validation dataset. I will continue to improve it as I follow the course, so stay tuned üòé\nThis post is based on the first lab of the fast.ai coure so thank you Jeremy Howard üòÉ"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AI baby",
    "section": "",
    "text": "Is it hacked?\n\n\n\n\n\n\n\nml-cybersecurity\n\n\n\n\n\n\n\n\n\n\n\nApr 15, 2023\n\n\nMihail Plesa\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Journal articles   \n\n    \n        A New Quantum Encryption Scheme\n    \n    \n        A quantum safe analysis of Helios voting system\n    \n    \n        Privacy-Preserving Clustering: A New Approach Based on Invariant Order Encryption\n    \n    \n        Self-repairing mechanical components using artificial Intelligence\n    \n    \n        Anonymous Spam Detection Service Based on Somewhat Homomorphic Encryption\n    \n    \n        A key agreement protocol based on spiking neural P systems with anti-spikes\n    \n\n Conference articles   \n\n        \n            Hybrid scheme for secure communications using quantum and classical mechanisms\n        \n        \n            Using quantum communications for maritime signal flags\n        \n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi there!\nMy name is Mihail (the guy next to that adorable little girl). I‚Äôm a research security engineer. This means I read research papers, publish new ideas and implement various cybersecurity tools. My research focuses on machine learning applications in cybersecurity and privacy. I‚Äôm also a Ph.D.¬†student at the Faculty of Mathematics and Informatics of the University of Bucharest. My thesis is about applications of Spiking Neural P systems in cybersecurity and especially in cryptography."
  },
  {
    "objectID": "presentations.html",
    "href": "presentations.html",
    "title": "Presentations",
    "section": "",
    "text": "How to implement a quantum key distribution protocol on IBM's quantum computer (a practical example of quantum programming)\n    DefCamp 2019 presentation\n  \n  \n    Augment cybersecurity through A.I.\n    DefCamp 2022 presentation\n  \n\n\nNo matching items"
  }
]